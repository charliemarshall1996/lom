{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Optimization\n",
    "\n",
    "The primary objective of this baseline optimization run is to establish a foundational performance benchmark for the Latent Dirichlet Allocation (LDA) model implemented via the Gensim library on a pre-processed corpus. This will serve as the starting point for subsequent parameter tuning and optimizations.\n",
    "\n",
    "## Purpose\n",
    "\n",
    "1. Establish Baseline Metrics: To determine the initial effectiveness of the LDA model in discovering coherent and meaningful topics from the corpus without any parameter tuning.\n",
    "2. Parameter Sensitivity Analysis: To identify which parameters have the most significant impact on the model's performance, providing a focused direction for detailed tuning.\n",
    "3. Computational Efficiency Evaluation: To assess the training time and resource utilization of the model under default settings, ensuring the scalability and practicality of further experiments.\n",
    "\n",
    "## Metrics for Evaluation\n",
    "\n",
    "- Topic Coherence (C_v): Measures the degree of semantic similarity between high scoring words in the topic. This metric will help in evaluating the interpretability and quality of the topics extracted by the model.\n",
    "- Perplexity: Evaluates how well the probability distribution predicted by the model matches the actual distribution of the words in the documents. Lower values indicate better fitting models.\n",
    "- Computation Time: Evaluates the time it takes to train the model for different parameter values. Lower computation time means that it was quicker to train the model, which is advantageous, but not indicative of better quality models.\n",
    "\n",
    "## Methodology\n",
    "1. Model Configuration\n",
    "    - Number of Topics (num_topics): Start with a mid-range value, such as 10 or 20, to gauge the granularity of topics extracted from the corpus.\n",
    "    - Learning Method: Use online learning with default parameters for initial runs to assess the model's adaptability to incremental data.\n",
    "    - Iterations and Passes: Set to default values to evaluate out-of-the-box convergence behavior of the model.\n",
    "2. Execution\n",
    "    - Training the Model: Utilize the pre-processed corpus to train the LDA model using the specified configurations.\n",
    "    - Logging and Monitoring: Record the training progress, including computation time and intermediate metric scores (coherence and perplexity) for each iteration.\n",
    "    - Per genre & meta: The training will be conducted on both on the entire dataset (meta), as well as per-genre. This will allow the establishment of a baseline for all cases, and allow or the identification of baseline differences between each genre.\n",
    "3. Post-Processing\n",
    "    - Topic Examination: Review the topics generated by the model for relevance and coherence.\n",
    "    - Metric Calculation: Compute the coherence and perplexity scores for the model.\n",
    "4. Documentation\n",
    "    - Reporting: Document all findings, including configurations, system utilization, and performance metrics.\n",
    "    - Recommendations for Optimization: Based on the baseline results, recommend parameters for subsequent tuning phases.\n",
    "\n",
    "## Expected Outcomes\n",
    "\n",
    "The execution of this plan is expected to yield a comprehensive understanding of the baseline capabilities of the LDA model on the given corpus. The results will guide further fine-tuning of the model parameters, with a specific focus on enhancing topic quality and optimizing computational resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training baseline meta model...\n",
      "Trained meta model after 31.76366686820984...\n",
      "Training baseline country model...\n",
      "Trained country model after 7.315662384033203...\n",
      "Training baseline rap model...\n",
      "Trained rap model after 12.06016492843628...\n",
      "Training baseline rb model...\n",
      "Trained rb model after 7.64744234085083...\n",
      "Training baseline pop model...\n",
      "Trained pop model after 7.286738872528076...\n",
      "Training baseline rock model...\n",
      "Trained rock model after 8.38888430595398...\n"
     ]
    }
   ],
   "source": [
    "# Import packages\n",
    "import time\n",
    "\n",
    "from gensim.models import CoherenceModel, LdaModel\n",
    "from gensim.corpora import Dictionary\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from src.utils import load_processed_dataset\n",
    "\n",
    "# Import data\n",
    "df = load_processed_dataset(\"../../../data/processed/song_lyrics_sampled_processed.csv\")\n",
    "\n",
    "# Separate into genres\n",
    "meta = df.lyrics\n",
    "country = df[df['tag'] == 'country'].lyrics\n",
    "rap = df[df['tag'] == 'rap'].lyrics\n",
    "rb = df[df['tag'] == 'rb'].lyrics\n",
    "pop = df[df['tag'] == 'pop'].lyrics\n",
    "rock = df[df['tag'] == 'rock'].lyrics\n",
    "\n",
    "# Extract features\n",
    "def bow_extract(texts):\n",
    "\n",
    "    # Create dictionary\n",
    "    dictionary = Dictionary(texts)\n",
    "\n",
    "    # Create corpus\n",
    "    corpus = [dictionary.doc2bow(doc) for doc in texts]\n",
    "\n",
    "    # Return\n",
    "    return dictionary, corpus\n",
    "\n",
    "meta_dct, meta_corpus = bow_extract(meta)\n",
    "country_dct, country_corpus = bow_extract(country)\n",
    "rap_dct, rap_corpus = bow_extract(rap)\n",
    "rb_dct, rb_corpus = bow_extract(rb)\n",
    "pop_dct, pop_corpus = bow_extract(pop)\n",
    "rock_dct, rock_corpus = bow_extract(rock)\n",
    "\n",
    "def train_baseline_model(genre, dct, corpus, lyrics):\n",
    "    print(f\"Training baseline {genre} model...\")\n",
    "    \n",
    "    baseline_data = {'genre': genre}\n",
    "    \n",
    "    start = time.time()\n",
    "    model = LdaModel(corpus=corpus, id2word=dct, num_topics=20)\n",
    "    end = time.time()\n",
    "    \n",
    "    print(f\"Trained {genre} model after {end-start}...\")\n",
    "    \n",
    "    model.save(f\"../../../models/sampled/baseline/{genre}_baseline.model\")\n",
    "    \n",
    "    baseline_data['time'] = end - start\n",
    "    \n",
    "    coh_model = CoherenceModel(model, texts=lyrics, dictionary=dct)\n",
    "    baseline_data['coherence'] = coh_model.get_coherence()\n",
    "    baseline_data['perplexity'] = model.log_perplexity(corpus)\n",
    "    return baseline_data\n",
    "\n",
    "baselines = []\n",
    "baselines.append(train_baseline_model('meta', meta_dct, meta_corpus, meta))\n",
    "baselines.append(train_baseline_model('country', country_dct, country_corpus, country))\n",
    "baselines.append(train_baseline_model('rap', rap_dct, rap_corpus, rap))\n",
    "baselines.append(train_baseline_model('rb', rb_dct, rb_corpus, rb))\n",
    "baselines.append(train_baseline_model('pop', pop_dct, pop_corpus, pop))\n",
    "baselines.append(train_baseline_model('rock', rock_dct, rock_corpus, rock))\n",
    "\n",
    "baseline_df = pd.DataFrame(baselines)\n",
    "baseline_df.to_csv(\"../../../data/optimization/baseline/baseline_performances.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
